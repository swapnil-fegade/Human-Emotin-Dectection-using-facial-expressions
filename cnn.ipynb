{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1b99K29xZLzhWIKa0Wr_WNjk6lv2P20PC","authorship_tag":"ABX9TyN8YcNEVclcO9XuWoBeUe0G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install tensorflow --upgrade"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"96H8ZnKTJcWi","executionInfo":{"status":"ok","timestamp":1749497090555,"user_tz":-330,"elapsed":83181,"user":{"displayName":"Swapnil Fegade","userId":"15888241361602724395"}},"outputId":"64d11b81-a2d0-42f2-b0e4-7d680ca38018"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Collecting tensorflow\n","  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n","Collecting tensorboard~=2.19.0 (from tensorflow)\n","  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n","Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n","  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n","Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m840.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, tensorflow\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.4.1\n","    Uninstalling ml-dtypes-0.4.1:\n","      Successfully uninstalled ml-dtypes-0.4.1\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.18.0\n","    Uninstalling tensorboard-2.18.0:\n","      Successfully uninstalled tensorboard-2.18.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.18.0\n","    Uninstalling tensorflow-2.18.0:\n","      Successfully uninstalled tensorflow-2.18.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\n","tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n","tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed ml-dtypes-0.5.1 tensorboard-2.19.0 tensorflow-2.19.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["ml_dtypes","tensorflow"]},"id":"13e452ce43404d89823a1d8379f3379d"}},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"txj3yne23sX4"},"outputs":[],"source":["# Import necessary libraries\n","import tensorflow as tf\n","from tensorflow.keras.layers import Activation, Convolution2D, Dropout, Conv2D\n","from tensorflow.keras.layers import AveragePooling2D, BatchNormalization\n","from tensorflow.keras.layers import GlobalAveragePooling2D\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import SeparableConv2D\n","from tensorflow.keras import layers\n","from tensorflow.keras.regularizers import l2\n","import os\n","from google.colab import drive"]},{"cell_type":"code","source":["# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define output directory in Google Drive\n","output_dir = '/content/drive/MyDrive/Capstone DL project/Models'\n","os.makedirs(output_dir, exist_ok=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V2huKkhS4k4_","executionInfo":{"status":"ok","timestamp":1749497151622,"user_tz":-330,"elapsed":3785,"user":{"displayName":"Swapnil Fegade","userId":"15888241361602724395"}},"outputId":"64936009-e0a1-4893-cb75-6147a66caf67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\n","# Define CNN model functions\n","def simple_CNN(input_shape, num_classes):\n","    model = Sequential()\n","    model.add(Convolution2D(filters=16, kernel_size=(7, 7), padding='same', name='image_array', input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(Convolution2D(filters=16, kernel_size=(7, 7), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n","    model.add(Dropout(.5))\n","\n","    model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n","    model.add(Dropout(.5))\n","\n","    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n","    model.add(Dropout(.5))\n","\n","    model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n","    model.add(Dropout(.5))\n","\n","    model.add(Convolution2D(filters=256, kernel_size=(3, 3), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Convolution2D(filters=num_classes, kernel_size=(3, 3), padding='same'))\n","    model.add(GlobalAveragePooling2D())\n","    model.add(Activation('softmax', name='predictions'))\n","    return model\n"],"metadata":{"id":"xqEyIUFR4q7g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def simpler_CNN(input_shape, num_classes):\n","    model = Sequential()\n","    model.add(Convolution2D(filters=16, kernel_size=(5, 5), padding='same', name='image_array', input_shape=input_shape))\n","    model.add(BatchNormalization())\n","    model.add(Convolution2D(filters=16, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(Dropout(.25))\n","\n","    model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Convolution2D(filters=32, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(Dropout(.25))\n","\n","    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Convolution2D(filters=64, kernel_size=(3, 3), strides=(2, 2), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(Dropout(.25))\n","\n","    model.add(Convolution2D(filters=64, kernel_size=(1, 1), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Convolution2D(filters=128, kernel_size=(3, 3), strides=(2, 2), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(Dropout(.25))\n","\n","    model.add(Convolution2D(filters=256, kernel_size=(1, 1), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Convolution2D(filters=128, kernel_size=(3, 3), strides=(2, 2), padding='same'))\n","\n","    model.add(Convolution2D(filters=256, kernel_size=(1, 1), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Convolution2D(filters=num_classes, kernel_size=(3, 3), strides=(2, 2), padding='same'))\n","\n","    model.add(Flatten())\n","    model.add(Activation('softmax', name='predictions'))\n","    return model\n"],"metadata":{"id":"yAseVolF7R8t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tiny_XCEPTION(input_shape, num_classes, l2_regularization=0.01):\n","    regularization = l2(l2_regularization)\n","    img_input = Input(input_shape)\n","\n","    # Base\n","    x = Conv2D(5, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(img_input)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = Conv2D(5, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    # Module 1\n","    residual = Conv2D(8, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n","    residual = BatchNormalization()(residual)\n","    x = SeparableConv2D(8, (3, 3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = SeparableConv2D(8, (3, 3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","    x = layers.Add()([x, residual])\n","\n","    # Module 2\n","    residual = Conv2D(16, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n","    residual = BatchNormalization()(residual)\n","    x = SeparableConv2D(16, (3, 3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = SeparableConv2D(16, (3, 3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","    x = layers.Add()([x, residual])\n","\n","    # Module 3\n","    residual = Conv2D(32, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n","    residual = BatchNormalization()(residual)\n","    x = SeparableConv2D(32, (3, 3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = SeparableConv2D(32, (3, 3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","    x = layers.Add()([x, residual])\n","\n","    # Module 4\n","    residual = Conv2D(64, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n","    residual = BatchNormalization()(residual)\n","    x = SeparableConv2D(64, (3, 3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = SeparableConv2D(64, (3, 3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","    x = layers.Add()([x, residual])\n","\n","    # Output\n","    x = Conv2D(num_classes, (3, 3), padding='same')(x)\n","    x = GlobalAveragePooling2D()(x)\n","    output = Activation('softmax', name='predictions')(x)\n","\n","    model = Model(img_input, output)\n","    return model\n"],"metadata":{"id":"ZBtJSmM07PR-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mini_XCEPTION(input_shape, num_classes, l2_regularization=0.01):\n","    regularization = l2(l2_regularization)\n","    img_input = Input(input_shape)\n","\n","    # Base\n","    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(img_input)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    # Module 1\n","    residual = Conv2D(16, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n","    residual = BatchNormalization()(residual)\n","    x = SeparableConv2D(16, (3, 3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = SeparableConv2D(16, (3, 3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","    x = layers.Add()([x, residual])\n","\n","    # Module 2\n","    residual = Conv2D(32, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n","    residual = BatchNormalization()(residual)\n","    x = SeparableConv2D(32, (3, 3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = SeparableConv2D(32, (3, 3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","    x = layers.Add()([x, residual])\n","\n","    # Module 3\n","    residual = Conv2D(64, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n","    residual = BatchNormalization()(residual)\n","    x = SeparableConv2D(64, (3, 3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = SeparableConv2D(64, (3, 3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","    x = layers.Add()([x, residual])\n","\n","    # Module 4\n","    residual = Conv2D(128, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n","    residual = BatchNormalization()(residual)\n","    x = SeparableConv2D(128, (3, 3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = SeparableConv2D(128, (3, 3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","    x = layers.Add()([x, residual])\n","\n","    # Output\n","    x = Conv2D(num_classes, (3, 3), padding='same')(x)\n","    x = GlobalAveragePooling2D()(x)\n","    output = Activation('softmax', name='predictions')(x)\n","\n","    model = Model(img_input, output)\n","    return model"],"metadata":{"id":"8oXU5ai46ntb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def big_XCEPTION(input_shape, num_classes):\n","    img_input = Input(input_shape)\n","\n","    # Base\n","    x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False)(img_input)\n","    x = BatchNormalization(name='block1_conv1_bn')(x)\n","    x = Activation('relu', name='block1_conv1_act')(x)\n","    x = Conv2D(64, (3, 3), use_bias=False)(x)\n","    x = BatchNormalization(name='block1_conv2_bn')(x)\n","    x = Activation('relu', name='block1_conv2_act')(x)\n","\n","    # Module 1\n","    residual = Conv2D(128, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n","    residual = BatchNormalization()(residual)\n","    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n","    x = BatchNormalization(name='block2_sepconv1_bn')(x)\n","    x = Activation('relu', name='block2_sepconv2_act')(x)\n","    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n","    x = BatchNormalization(name='block2_sepconv2_bn')(x)\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","    x = layers.Add()([x, residual])\n","\n","    # Module 2\n","    residual = Conv2D(256, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n","    residual = BatchNormalization()(residual)\n","    x = Activation('relu', name='block3_sepconv1_act')(x)\n","    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n","    x = BatchNormalization(name='block3_sepconv1_bn')(x)\n","    x = Activation('relu', name='block3_sepconv2_act')(x)\n","    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n","    x = BatchNormalization(name='block3_sepconv2_bn')(x)\n","    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","    x = layers.Add()([x, residual])\n","\n","    # Output\n","    x = Conv2D(num_classes, (3, 3), padding='same')(x)\n","    x = GlobalAveragePooling2D()(x)\n","    output = Activation('softmax', name='predictions')(x)\n","\n","    model = Model(img_input, output)\n","    return model"],"metadata":{"id":"i6qjQj2M4wYI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Main execution\n","if __name__ == \"__main__\":\n","    input_shape = (48, 48, 1)  # Adjusted to match simple_CNN\n","    num_classes = 7\n","\n","    # Create and summarize simple_CNN model\n","    model = simple_CNN(input_shape, num_classes)\n","\n","    # Save model summary to a text file in Google Drive\n","    with open(os.path.join(output_dir, 'simple_CNN_summary.txt'), 'w') as f:\n","        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n","\n","    print(\"Model summary saved to Google Drive at:\", os.path.join(output_dir, 'simple_CNN_summary.txt'))\n","\n","\n","    model = tiny_XCEPTION(input_shape, num_classes)\n","    with open(os.path.join(output_dir, 'tiny_XCEPTION_summary.txt'), 'w') as f:\n","        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n","\n","    print(\"Model mummary saved to Google drive at:\", os.path.join(output_dir, 'tiny_XCEPTION_summary.txt'))\n","\n","    model = mini_XCEPTION(input_shape, num_classes)\n","    with open(os.path.join(output_dir, 'mini_XCEPTION_summary.txt'), 'w') as f:\n","        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n","\n","    print(\"Model summary saved to Google Drive at:\", os.path.join(output_dir, 'mini_XCEPTION_summary.txt'))\n","\n","    model = big_XCEPTION(input_shape, num_classes)\n","    with open(os.path.join(output_dir, 'big_XCEPTION_summary.txt'), 'w') as f:\n","        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n","\n","    print(\"Model summary saved to Google Drive at:\", os.path.join(output_dir, 'big_XCEPTION_summary.txt'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"CqfKpDa74tqv","executionInfo":{"status":"ok","timestamp":1749497476659,"user_tz":-330,"elapsed":1360,"user":{"displayName":"Swapnil Fegade","userId":"15888241361602724395"}},"outputId":"ede80bbe-aefd-4e4f-9d81-ab8583b383e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model summary saved to Google Drive at: /content/drive/MyDrive/Capstone DL project/Models/simple_CNN_summary.txt\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model mummary saved to Google drive at: /content/drive/MyDrive/Capstone DL project/Models/tiny_XCEPTION_summary.txt\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model summary saved to Google Drive at: /content/drive/MyDrive/Capstone DL project/Models/mini_XCEPTION_summary.txt\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model summary saved to Google Drive at: /content/drive/MyDrive/Capstone DL project/Models/big_XCEPTION_summary.txt\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"rKMsJoY2GKPr"},"execution_count":null,"outputs":[]}]}