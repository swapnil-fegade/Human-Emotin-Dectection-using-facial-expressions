{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO7symwsuf6yn1ZW8RViVFf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"awpmrsQuS-jU","executionInfo":{"status":"ok","timestamp":1749583711806,"user_tz":-330,"elapsed":3136,"user":{"displayName":"Swapnil Fegade","userId":"15888241361602724395"}},"outputId":"e8262402-dbe3-44c7-ab7b-1b1825a55dd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","Requirement already satisfied: imutils in /usr/local/lib/python3.11/dist-packages (0.5.4)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n","Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n","Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n","Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.32.4)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n","Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n","Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.5)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n","Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.12)\n","Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n","Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n","Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n","Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}],"source":["# Install required libraries\n","!pip install gradio opencv-python-headless imutils tensorflow numpy"]},{"cell_type":"code","source":["# Mount Google Drive to access the model file\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JzEDToQyTS2Z","executionInfo":{"status":"ok","timestamp":1749646298104,"user_tz":-330,"elapsed":23416,"user":{"displayName":"Swapnil Fegade","userId":"15888241361602724395"}},"outputId":"2cab4374-8914-4d31-a36e-4e8c68d20e0f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import gradio as gr\n","import imutils\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.models import load_model"],"metadata":{"id":"SlX70WAoTUVq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download Haar cascade file\n","!wget https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_frontalface_default.xml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RzGkg35TTWcP","executionInfo":{"status":"ok","timestamp":1749583874386,"user_tz":-330,"elapsed":911,"user":{"displayName":"Swapnil Fegade","userId":"15888241361602724395"}},"outputId":"9ff3f4fd-f44a-4cf4-9aee-918367231548"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-06-10 19:31:15--  https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_frontalface_default.xml\n","Resolving github.com (github.com)... 20.27.177.113\n","Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml [following]\n","--2025-06-10 19:31:15--  https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 930127 (908K) [text/plain]\n","Saving to: ‘haarcascade_frontalface_default.xml’\n","\n","haarcascade_frontal 100%[===================>] 908.33K  3.42MB/s    in 0.3s    \n","\n","2025-06-10 19:31:16 (3.42 MB/s) - ‘haarcascade_frontalface_default.xml’ saved [930127/930127]\n","\n"]}]},{"cell_type":"code","source":["# Parameters for loading data and models\n","detection_model_path = 'haarcascade_frontalface_default.xml'\n","emotion_model_path = '/content/drive/MyDrive/Capstone DL project/final_mini_XCEPTION_model_v2.keras'"],"metadata":{"id":"7k3NV_WNTVYE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load models\n","try:\n","    face_detection = cv2.CascadeClassifier(detection_model_path)\n","    if not face_detection.empty():\n","        print(\"Haar cascade loaded successfully\")\n","    else:\n","        raise ValueError(\"Failed to load Haar cascade file\")\n","except Exception as e:\n","    print(f\"Error loading Haar cascade: {e}\")\n","\n","try:\n","    emotion_classifier = load_model(emotion_model_path, compile=False)\n","    print(\"Emotion model loaded successfully\")\n","except Exception as e:\n","    print(f\"Error loading emotion model: {e}\")\n","    raise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8E71dtOTTXyW","executionInfo":{"status":"ok","timestamp":1749585439961,"user_tz":-330,"elapsed":300,"user":{"displayName":"Swapnil Fegade","userId":"15888241361602724395"}},"outputId":"58fb0edb-e3c0-4d64-e649-e8c9a58144b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Haar cascade loaded successfully\n","Emotion model loaded successfully\n"]}]},{"cell_type":"code","source":["\n","# Define emotions (ensure these match your model's output classes)\n","EMOTIONS = [\"angry\", \"disgust\", \"scared\", \"happy\", \"sad\", \"surprised\", \"neutral\"]\n"],"metadata":{"id":"YAJjA-uaTabS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_frame(frame):\n","    try:\n","        # Ensure frame is in correct format (numpy array, BGR)\n","        if frame is None:\n","            return None, \"No frame received\"\n","\n","        # Resize and convert frame\n","        frame = imutils.resize(frame, width=300)\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        frameClone = frame.copy()\n","        canvas = np.zeros((250, 300, 3), dtype=\"uint8\")\n","\n","        # Detect faces\n","        faces = face_detection.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n","\n","        label = \"No face detected\"\n","        if len(faces) > 0:\n","            # Sort faces by size and take the largest one\n","            faces = sorted(faces, reverse=True, key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n","            (fX, fY, fW, fH) = faces\n","\n","            # Extract and preprocess ROI\n","            roi = gray[fY:fY + fH, fX:fX + fW]\n","            roi = cv2.resize(roi, (48, 48))  # Changed to 48x48 to match model input\n","            roi = roi.astype(\"float\") / 255.0\n","            roi = img_to_array(roi)\n","            roi = np.expand_dims(roi, axis=0)\n","\n","            # Predict emotions\n","            preds = emotion_classifier.predict(roi)[0]\n","            emotion_probability = np.max(preds)\n","            label = EMOTIONS[preds.argmax()]\n","\n","            # Draw probability bars\n","            for (i, (emotion, prob)) in enumerate(zip(EMOTIONS, preds)):\n","                text = \"{}: {:.2f}%\".format(emotion, prob * 100)\n","                w = int(prob * 300)\n","                cv2.rectangle(canvas, (7, (i * 35) + 5), (w, (i * 35) + 35), (0, 0, 255), -1)\n","                cv2.putText(canvas, text, (10, (i * 35) + 23), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 255, 255), 2)\n","\n","            # Draw face rectangle and label\n","            cv2.putText(frameClone, label, (fX, fY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n","            cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH), (0, 0, 255), 2)\n","\n","        # Combine frame and canvas for display\n","        output = np.vstack([frameClone, canvas])\n","        return output, label\n","    except Exception as e:\n","        return frame, f\"Error processing frame: {str(e)}\""],"metadata":{"id":"SWlhFElPTbm6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gradio interface\n","iface = gr.Interface(\n","    fn=process_frame,\n","    inputs=gr.Image(type=\"numpy\", label=\"Webcam Input\"),  # Removed 'source' parameter\n","    outputs=[gr.Image(type=\"numpy\", label=\"Processed Frame\"), gr.Textbox(label=\"Detected Emotion\")],\n","    live=True,  # Enables real-time streaming\n","    title=\"Facial Emotion Detection\",\n","    description=\"This app detects emotions from a Mini XCEPTION model. Ensure your webcam is enabled.\"\n",")"],"metadata":{"id":"d9cPK4anTdH0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Launch the interface\n","iface.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":646},"id":"r8SntHEJTeG3","executionInfo":{"status":"ok","timestamp":1749585449516,"user_tz":-330,"elapsed":1957,"user":{"displayName":"Swapnil Fegade","userId":"15888241361602724395"}},"outputId":"a8ed3c8d-d15e-45ff-c387-acc7c3610bf5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://54a643f5ce766de351.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://54a643f5ce766de351.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["\n","# ### Steps to Run in Colab:\n","# 1. **Mount Google Drive**: When you run the code, Colab will prompt you to mount your Google Drive. Follow the instructions to authenticate and mount it, ensuring the model file is accessible at `/content/drive/MyDrive/Capstone DL project/best_mini_XCEPTION.keras`.\n","# 2. **Verify Model Compatibility**:\n","#    - **Input Shape**: Check your model's architecture to confirm it expects 64x64 grayscale images. You can inspect the model with `emotion_classifier.summary()` after loading it. If the input shape is different (e.g., 48x48), update the line `roi = cv2.resize(roi, (64, 64))` to match (e.g., `roi = cv2.resize(roi, (48, 48))`).\n","#    - **Output Classes**: Ensure the model outputs 7 classes corresponding to `EMOTIONS`. If the number or order of classes differs, update the `EMOTIONS` list to match your model's output layer.\n","# 3. **Run the Code**: Execute the cells in Colab. The Haar cascade file will be downloaded automatically, and your model will be loaded from Google Drive.\n","# 4. **Gradio Interface**: After launching, Gradio will provide a public URL (or local interface) to access the webcam feed. Ensure your browser allows webcam access.\n","# 5. **Troubleshooting**:\n","#    - If the model fails to load, check the file path and ensure the `.keras` file is not corrupted.\n","#    - If you get a `ValueError` about custom objects, you may need to define any custom layers or metrics used during training. For example, if your model uses a custom loss, you might need to load it with `custom_objects={'loss_name': loss_function}`.\n","#    - If no faces are detected, adjust the `detectMultiScale` parameters (e.g., lower `minNeighbors` or `scaleFactor`) for better detection.\n","\n","# ### Potential Issues and Fixes:\n","# - **Model Input Mismatch**: If your model expects a different input shape, the code will fail during prediction. Check the model’s input shape and adjust the resize step accordingly.\n","# - **Class Mismatch**: If your model was trained on fewer or different emotions, the `EMOTIONS` list and indexing will cause errors. Update the list to match your model’s classes.\n","# - **Google Drive Access**: Ensure the model file is in the specified path. If it’s in a different folder, update `emotion_model_path`.\n","# - **Gradio Webcam Issues**: Colab’s webcam access via Gradio can be finicky. If the webcam doesn’t work, ensure your browser permissions allow camera access, or test with a local Python environment if possible.\n","\n","# ### Testing the Model:\n","# To verify your model’s compatibility before running the full Gradio interface, you can add this snippet after loading the model:\n","\n","# ```python\n","# # Check model summary\n","# emotion_classifier.summary()\n","\n","# # Test with a dummy input\n","# dummy_input = np.zeros((1, 64, 64, 1))  # Adjust shape if needed\n","# try:\n","#     preds = emotion_classifier.predict(dummy_input)\n","#     print(f\"Model output shape: {preds.shape}\")\n","#     print(f\"Predicted probabilities: {preds}\")\n","# except Exception as e:\n","#     print(f\"Error with model prediction: {e}\")\n","# ```\n","\n","# This will confirm the model’s input/output shapes and help diagnose issues.\n","\n","# ### Additional Notes:\n","# - The code retains the same functionality as the original: it detects faces, predicts emotions, draws bounding boxes, and displays probability bars.\n","# - The commented-out emoji overlay from the original code is omitted for simplicity, as it requires additional image files. If you want to include it, upload the emoji images to your Google Drive and add the overlay logic back (uncomment and adapt the relevant section).\n","# - If you encounter performance issues in Colab (e.g., slow processing), consider optimizing the frame rate or using a local machine with a GPU for better performance.\n","\n","# Let me know if you need help verifying your model’s specifications, debugging errors, or adding the emoji overlay!"],"metadata":{"id":"WHzKTP3DTezy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4TQScD7GhBpB"},"execution_count":null,"outputs":[]}]}